{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory paths for train, validation, and test sets\n",
    "train_directory = \"/Users/lukasiwan/NeueFische/Repositories/Hydroponics/data/train_data\"\n",
    "test_directory = \"/Users/lukasiwan/NeueFische/Repositories/Hydroponics/data/test_data\"\n",
    "\n",
    "batch_size = 7\n",
    "image_size = (50,50)\n",
    "epoch_size = 150 #200 best with 94%\n",
    "fold_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the KFold object\n",
    "kfold = KFold(n_splits=fold_size, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store the fold results\n",
    "fold_train_loss = []\n",
    "fold_train_accuracy = []\n",
    "fold_test_loss = []\n",
    "fold_test_accuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform k-fold cross-validation\n",
    "fold = 1\n",
    "for train_index, val_index in kfold.split(os.listdir(train_directory)):\n",
    "    print(f\"Fold {fold}:\")\n",
    "\n",
    "    # Load and preprocess the data for training set\n",
    "    train_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        train_directory,\n",
    "        batch_size=batch_size,\n",
    "        image_size=image_size,\n",
    "        seed=42, \n",
    "    )\n",
    "\n",
    "    # Load and preprocess the data for test set\n",
    "    test_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        test_directory,\n",
    "        batch_size=batch_size,\n",
    "        image_size=image_size,\n",
    "        seed=42,\n",
    "    )\n",
    "\n",
    "    # Define data augmentation\n",
    "    data_augmentation = tf.keras.Sequential([\n",
    "        preprocessing.Rescaling(1./255),\n",
    "        preprocessing.Resizing(image_size[0], image_size[1]),\n",
    "        preprocessing.RandomFlip(\"horizontal\"),\n",
    "        preprocessing.RandomRotation(0.3),\n",
    "        #preprocessing.RandomZoom(0.1),\n",
    "    ])\n",
    "\n",
    "    # Define the model architecture\n",
    "    model = Sequential([\n",
    "        data_augmentation,\n",
    "        Conv2D(32, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        Dropout(0.25),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        Dropout(0.25),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(4, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(train_data, epochs=epoch_size, validation_data=test_data)\n",
    "\n",
    "    # Store the fold results\n",
    "    fold_train_loss.append(history.history['loss'])\n",
    "    fold_train_accuracy.append(history.history['accuracy'])\n",
    "    fold_test_loss.append(history.history['val_loss'])\n",
    "    fold_test_accuracy.append(history.history['val_accuracy'])\n",
    "\n",
    "    fold += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training and testing history\n",
    "train_loss = np.mean(fold_train_loss, axis=0)\n",
    "train_accuracy = np.mean(fold_train_accuracy, axis=0)\n",
    "test_loss = np.mean(fold_test_loss, axis=0)  # renaming from val_loss to test_loss\n",
    "test_accuracy = np.mean(fold_test_accuracy, axis=0)  # renaming from val_accuracy to test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the validation data\n",
    "test_loss, test_accuracy = model.evaluate(test_data)\n",
    "print(\"Validation Loss:\", test_loss)\n",
    "print(\"Validation Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training history\n",
    "train_loss = history.history['loss']\n",
    "train_accuracy = history.history['accuracy']\n",
    "val_loss = history.history['val_loss']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "# Create line plots\n",
    "epochs = range(1, len(train_loss) + 1)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, train_accuracy, label='Training Accuracy')\n",
    "plt.plot(epochs, val_accuracy, label='Validation Accuracy')\n",
    "plt.title(f'Training and Validation Accuracy\\n(Epochs: {epoch_size}, Batch Size: {batch_size}, Image Size: {image_size[0]}x{image_size[1]})')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, train_loss, label='Training Loss')\n",
    "plt.plot(epochs, val_loss, label='Validation Loss')\n",
    "plt.title(f'Training and Validation Loss\\n(Epochs: {epoch_size}, Batch Size: {batch_size}, Image Size: {image_size[0]}x{image_size[1]})')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
